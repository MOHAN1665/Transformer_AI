{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26fa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding, pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385c55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AirlineTweets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b61316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'airline_sentiment']].dropna()\n",
    "df = df[df['airline_sentiment'].isin(['positive', 'neutral', 'negative'])]\n",
    "df = df.sample(300, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f4a4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SouthwestAir you're my early frontrunner for ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USAirways how is it that my flt to EWR was Ca...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@JetBlue what is going on with your BDL to DCA...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@JetBlue do they have to depart from Washingto...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@JetBlue I can probably find some of them. Are...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>@united, no, your service here pretty much rui...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>@southwestair thanks for taking it up a notch!...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>THE END: RT @USAirways: Reminder: From 2/28, w...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>@JetBlue Awww thank you B6! Glad to hear it!  ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>@united We waited 40 min for our bags after a ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text airline_sentiment\n",
       "0    @SouthwestAir you're my early frontrunner for ...          positive\n",
       "1    @USAirways how is it that my flt to EWR was Ca...          negative\n",
       "2    @JetBlue what is going on with your BDL to DCA...          negative\n",
       "3    @JetBlue do they have to depart from Washingto...           neutral\n",
       "4    @JetBlue I can probably find some of them. Are...          negative\n",
       "..                                                 ...               ...\n",
       "295  @united, no, your service here pretty much rui...          negative\n",
       "296  @southwestair thanks for taking it up a notch!...          positive\n",
       "297  THE END: RT @USAirways: Reminder: From 2/28, w...           neutral\n",
       "298  @JetBlue Awww thank you B6! Glad to hear it!  ...          positive\n",
       "299  @united We waited 40 min for our bags after a ...          negative\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59185f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5057af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e408d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355bec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({**train_encodings, 'label': train_labels})\n",
    "val_dataset = Dataset.from_dict({**val_encodings, 'label': val_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d870e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b5a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a51646",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=False,  # 👈 Disable this\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5773dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d724ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,  # 👈 Add this line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222ab252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db475cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.942400</td>\n",
       "      <td>1.105076</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.352015</td>\n",
       "      <td>0.266944</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.808800</td>\n",
       "      <td>1.027917</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.352015</td>\n",
       "      <td>0.266944</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.733500</td>\n",
       "      <td>0.970528</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.352015</td>\n",
       "      <td>0.266944</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=90, training_loss=0.8282145818074544, metrics={'train_runtime': 103.2623, 'train_samples_per_second': 6.973, 'train_steps_per_second': 0.872, 'total_flos': 10990850484960.0, 'train_loss': 0.8282145818074544, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96fd6bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation Results:\n",
      "eval_loss: 0.9705\n",
      "eval_accuracy: 0.5167\n",
      "eval_f1: 0.3520\n",
      "eval_precision: 0.2669\n",
      "eval_recall: 0.5167\n",
      "eval_runtime: 1.6016\n",
      "eval_samples_per_second: 37.4620\n",
      "eval_steps_per_second: 4.9950\n",
      "epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Show evaluation metrics\n",
    "print(\"📊 Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be01074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fine-tuned-airline-model\\\\tokenizer_config.json',\n",
       " 'fine-tuned-airline-model\\\\special_tokens_map.json',\n",
       " 'fine-tuned-airline-model\\\\vocab.txt',\n",
       " 'fine-tuned-airline-model\\\\added_tokens.json',\n",
       " 'fine-tuned-airline-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"fine-tuned-airline-model\")\n",
    "tokenizer.save_pretrained(\"fine-tuned-airline-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1c3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        31\n",
      "           1       1.00      0.08      0.15        12\n",
      "           2       1.00      0.12      0.21        17\n",
      "\n",
      "    accuracy                           0.57        60\n",
      "   macro avg       0.85      0.40      0.36        60\n",
      "weighted avg       0.76      0.57      0.45        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Compare with traditional classifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3611bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "\n",
    "# # New text to predict\n",
    "# new_texts = [\"The service was amazing and staff was friendly.\"]\n",
    "# encodings = tokenizer(new_texts, truncation=True, padding=True)\n",
    "# dataset = Dataset.from_dict({**encodings})\n",
    "\n",
    "# # Get predictions\n",
    "# predictions = trainer.predict(dataset)\n",
    "# pred_labels = predictions.predictions.argmax(axis=-1)\n",
    "\n",
    "# # Convert numeric labels back to text\n",
    "# pred_class_names = label_encoder.inverse_transform(pred_labels)\n",
    "# print(list(zip(new_texts, pred_class_names)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89b9d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'negative', 'score': 0.4736349284648895}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"fine-tuned-airline-model\",\n",
    "    tokenizer=\"fine-tuned-airline-model\",\n",
    "    top_k=1\n",
    ")\n",
    "\n",
    "label_map = {f\"LABEL_{i}\": name for i, name in enumerate(label_encoder.classes_)}\n",
    "\n",
    "result = classifier(\"We had comfy seats and great snacks!\")[0][0]  # two [0]s\n",
    "result[\"label\"] = label_map[result[\"label\"]]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ee8a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 185, 1: 62, 2: 53})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334048a1",
   "metadata": {},
   "source": [
    "# The above DF is Imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea4699d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    185\n",
      "1    185\n",
      "2    185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "# Separate classes\n",
    "df_majority = df[df.label == 0]\n",
    "df_minority_1 = df[df.label == 1]\n",
    "df_minority_2 = df[df.label == 2]\n",
    "\n",
    "# Upsample minority classes\n",
    "df_minority_1_upsampled = resample(df_minority_1, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_minority_2_upsampled = resample(df_minority_2, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "# Combine\n",
    "train_df_balanced = pd.concat([df_majority, df_minority_1_upsampled, df_minority_2_upsampled])\n",
    "\n",
    "print(train_df_balanced[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c53194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f8cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2d39ac0",
   "metadata": {},
   "source": [
    "# Using Uncased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09fc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df860016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Load data\n",
    "df = pd.read_csv(\"AirlineTweets.csv\")\n",
    "df = df[['text', 'airline_sentiment']].dropna()\n",
    "df = df[df['airline_sentiment'].isin(['positive', 'neutral', 'negative'])]\n",
    "df = df.sample(500, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9e6014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6be35d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣ Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed3e35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Balance dataset by upsampling minority classes\n",
    "df_majority = df[df.label == 0]  # usually 'negative'\n",
    "df_minority_1 = df[df.label == 1]\n",
    "df_minority_2 = df[df.label == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d28e430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_1_upsampled = resample(df_minority_1, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_minority_2_upsampled = resample(df_minority_2, replace=True, n_samples=len(df_majority), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98928da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after balancing:\n",
      "label\n",
      "0    309\n",
      "1    309\n",
      "2    309\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df_balanced = pd.concat([df_majority, df_minority_1_upsampled, df_minority_2_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Class distribution after balancing:\")\n",
    "print(train_df_balanced['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9ca78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣ Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df_balanced['text'].tolist(),\n",
    "    train_df_balanced['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f7f5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ Tokenization\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ab117a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({**train_encodings, 'label': train_labels})\n",
    "val_dataset = Dataset.from_dict({**val_encodings, 'label': val_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23941520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6️⃣ Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e4ec246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7️⃣ Metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de259ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8️⃣ Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccb74619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9️⃣ Trainer setup\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "652f2558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [279/279 04:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.828400</td>\n",
       "      <td>0.480772</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.834323</td>\n",
       "      <td>0.836406</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294100</td>\n",
       "      <td>0.295686</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.918685</td>\n",
       "      <td>0.919011</td>\n",
       "      <td>0.919355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.274273</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.919077</td>\n",
       "      <td>0.918882</td>\n",
       "      <td>0.919355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🔟 Train & evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "684aa4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluation Results:\n",
      "eval_loss: 0.2743\n",
      "eval_accuracy: 0.9194\n",
      "eval_f1: 0.9191\n",
      "eval_precision: 0.9189\n",
      "eval_recall: 0.9194\n",
      "eval_runtime: 4.8978\n",
      "eval_samples_per_second: 37.9760\n",
      "eval_steps_per_second: 4.9000\n",
      "epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📊 Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3443287a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fine-tuned-airline-model_new\\\\tokenizer_config.json',\n",
       " 'fine-tuned-airline-model_new\\\\special_tokens_map.json',\n",
       " 'fine-tuned-airline-model_new\\\\vocab.txt',\n",
       " 'fine-tuned-airline-model_new\\\\added_tokens.json',\n",
       " 'fine-tuned-airline-model_new\\\\tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1️⃣1️⃣ Save model\n",
    "model.save_pretrained(\"fine-tuned-airline-model_new\")\n",
    "tokenizer.save_pretrained(\"fine-tuned-airline-model_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cbebfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 We had comfy seats and great snacks! → {'label': 'positive', 'score': 0.949704647064209}\n",
      "📝 The flight was delayed for 3 hours. → {'label': 'negative', 'score': 0.9571847319602966}\n",
      "📝 It was just an average flight, nothing special. → {'label': 'negative', 'score': 0.8188926577568054}\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣2️⃣ Prediction pipeline\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"fine-tuned-airline-model_new\",\n",
    "    tokenizer=\"fine-tuned-airline-model_new\",\n",
    "    top_k=1\n",
    ")\n",
    "\n",
    "label_map = {f\"LABEL_{i}\": name for i, name in enumerate(label_encoder.classes_)}\n",
    "\n",
    "test_texts = [\n",
    "    \"We had comfy seats and great snacks!\",\n",
    "    \"The flight was delayed for 3 hours.\",\n",
    "    \"It was just an average flight, nothing special.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = classifier(text)[0][0]\n",
    "    result[\"label\"] = label_map[result[\"label\"]]\n",
    "    print(f\"📝 {text} → {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23f2e49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 It was just an average flight, nothing special. → {'label': 'positive', 'score': 0.6625651121139526}\n"
     ]
    }
   ],
   "source": [
    "result = classifier(\"The flight was smooth and the crew was very kind.\")[0][0]\n",
    "result[\"label\"] = label_map[result[\"label\"]]\n",
    "print(f\"📝 {text} → {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bdfab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 It was just an average flight, nothing special. → {'label': 'neutral', 'score': 0.833930492401123}\n"
     ]
    }
   ],
   "source": [
    "result = classifier(\"The flight departed on time and landed as scheduled.\")[0][0]\n",
    "result[\"label\"] = label_map[result[\"label\"]]\n",
    "print(f\"📝 {text} → {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b88908d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c0452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d592e55c",
   "metadata": {},
   "source": [
    "# Using Cased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2e198cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: transformers <command> [<args>]\n",
      "Transformers CLI tool: error: argument {chat,convert,download,env,run,serve,add-new-model-like,add-fast-image-processor}: invalid choice: 'cache' (choose from 'chat', 'convert', 'download', 'env', 'run', 'serve', 'add-new-model-like', 'add-fast-image-processor')\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli cache clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d89bf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Load and preprocess data\n",
    "df = pd.read_csv(\"AirlineTweets.csv\")\n",
    "df = df[['text', 'airline_sentiment']].dropna()\n",
    "df = df[df['airline_sentiment'].isin(['positive', 'neutral', 'negative'])]\n",
    "df = df.sample(300, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 2️⃣ Encode labels numerically\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb455862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Balance dataset by upsampling minority classes\n",
    "df_majority = df[df.label == 0]  # Usually 'negative'\n",
    "df_minority_1 = df[df.label == 1]\n",
    "df_minority_2 = df[df.label == 2]\n",
    "\n",
    "df_minority_1_upsampled = resample(\n",
    "    df_minority_1, replace=True, n_samples=len(df_majority), random_state=42\n",
    ")\n",
    "df_minority_2_upsampled = resample(\n",
    "    df_minority_2, replace=True, n_samples=len(df_majority), random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5db6f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after balancing:\n",
      "label\n",
      "1    185\n",
      "2    185\n",
      "0    185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df_balanced = pd.concat(\n",
    "    [df_majority, df_minority_1_upsampled, df_minority_2_upsampled]\n",
    ").sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Class distribution after balancing:\")\n",
    "print(train_df_balanced['label'].value_counts())\n",
    "\n",
    "# 4️⃣ Train-validation split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df_balanced['text'].tolist(),\n",
    "    train_df_balanced['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98881c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10365208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5fdab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ Tokenize texts with cased tokenizer\n",
    "checkpoint = \"distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts, truncation=True, padding=True, max_length=512\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_texts, truncation=True, padding=True, max_length=512\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_dict({**train_encodings, 'label': train_labels})\n",
    "val_dataset = Dataset.from_dict({**val_encodings, 'label': val_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24c8494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6️⃣ Load pretrained cased model with classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=3\n",
    ")\n",
    "\n",
    "# 7️⃣ Define metrics function for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebd5536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8️⃣ Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ca55d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9️⃣ Initialize Trainer\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52a1f695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 03:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.041900</td>\n",
       "      <td>0.851965</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.679225</td>\n",
       "      <td>0.679331</td>\n",
       "      <td>0.693694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>0.538313</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.811302</td>\n",
       "      <td>0.814353</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>0.418242</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.849688</td>\n",
       "      <td>0.856399</td>\n",
       "      <td>0.846847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🔟 Train and evaluate the model\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "624a0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluation Results:\n",
      "eval_loss: 0.4182\n",
      "eval_accuracy: 0.8468\n",
      "eval_f1: 0.8497\n",
      "eval_precision: 0.8564\n",
      "eval_recall: 0.8468\n",
      "eval_runtime: 3.4611\n",
      "eval_samples_per_second: 32.0700\n",
      "eval_steps_per_second: 4.0450\n",
      "epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📊 Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00182fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣1️⃣ Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"fine-tuned-airline-model-cased\")\n",
    "tokenizer.save_pretrained(\"fine-tuned-airline-model-cased\")\n",
    "\n",
    "# 1️⃣2️⃣ Create pipeline for prediction\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"fine-tuned-airline-model-cased\",\n",
    "    tokenizer=\"fine-tuned-airline-model-cased\",\n",
    "    top_k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52c7a904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 We had comfy seats and great snacks! → {'label': 'positive', 'score': 0.8717353343963623}\n",
      "📝 The flight was delayed for 3 hours. → {'label': 'negative', 'score': 0.6469522714614868}\n",
      "📝 It was just an average flight, nothing special. → {'label': 'negative', 'score': 0.6606147289276123}\n"
     ]
    }
   ],
   "source": [
    "# Map model labels (LABEL_0, LABEL_1, LABEL_2) back to sentiment strings\n",
    "label_map = {f\"LABEL_{i}\": label for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "# Test some example texts\n",
    "test_texts = [\n",
    "    \"We had comfy seats and great snacks!\",\n",
    "    \"The flight was delayed for 3 hours.\",\n",
    "    \"It was just an average flight, nothing special.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = classifier(text)[0][0]  # Extract the dict inside the nested list\n",
    "    result[\"label\"] = label_map[result[\"label\"]]\n",
    "    print(f\"📝 {text} → {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c55a42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
